{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a16f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from brukeropusreader import read_file\n",
    "from scipy.interpolate import interp1d\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24281819",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Define folder paths (corrected paths for RE and OE)\n",
    "folder_path_oe = 'Spectra RE'  # OE data actually in 'Spectra RE'\n",
    "folder_path_re = 'Spectra OE'  # RE data actually in 'Spectra OE'\n",
    "folder_path_trachea = 'Spectra TR'  # Trachea data is correct\n",
    "\n",
    "# Function to list files in a folder\n",
    "def list_files(folder_path):\n",
    "    files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "    return files\n",
    "\n",
    "# List files in each folder\n",
    "files_re = list_files(folder_path_re)  # Actually RE data in 'Spectra OE'\n",
    "files_oe = list_files(folder_path_oe)  # Actually OE data in 'Spectra RE'\n",
    "files_tr = list_files(folder_path_trachea)  # Trachea data in 'Spectra TR'\n",
    "\n",
    "# Displaying file names and their count\n",
    "print(\"RE Folder:\")\n",
    "print(f\"Number of files: {len(files_re)}\")\n",
    "print(\"Files:\", files_re)\n",
    "\n",
    "print(\"\\nOE Folder:\")\n",
    "print(f\"Number of files: {len(files_oe)}\")\n",
    "print(\"Files:\", files_oe)\n",
    "\n",
    "print(\"\\nTrachea Folder:\")\n",
    "print(f\"Number of files: {len(files_tr)}\")\n",
    "print(\"Files:\", files_tr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26801c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the common set of wavenumbers\n",
    "start_wavenumber = 5000  # Starting wavenumber\n",
    "end_wavenumber = 400  # Ending wavenumber\n",
    "resolution = 1  # Resolution in cm⁻¹\n",
    "\n",
    "# Generate the common set of wavenumbers\n",
    "common_wavenumbers = np.arange(start_wavenumber, end_wavenumber - resolution, -resolution)\n",
    "\n",
    "# Verify the first and last values as well as the size of the set to ensure it matches expectations\n",
    "print(\"First wavenumber:\", common_wavenumbers[0])\n",
    "print(\"Last wavenumber:\", common_wavenumbers[-1])\n",
    "print(\"Total number of points:\", len(common_wavenumbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a131bc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wavenumbers(file_path):\n",
    "    opus_data = read_file(file_path)\n",
    "    # Assuming wavenumbers are stored in a key 'WN' in the returned data\n",
    "    num_points = len(opus_data['AB'])\n",
    "    start_wn = opus_data['AB Data Parameter']['FXV']\n",
    "    end_wn = opus_data['AB Data Parameter']['LXV']\n",
    "    # Generate the list of wavenumbers\n",
    "    wavenumbers = np.linspace(start_wn, end_wn, num_points)\n",
    "    return wavenumbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d5dcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectral_data(file_path):\n",
    "    \"\"\"\n",
    "    Extracts spectral data (e.g., absorbance values) from a file.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: The path to the Bruker file.\n",
    "\n",
    "    Returns:\n",
    "    - A numpy array containing the spectral data.\n",
    "    \"\"\"\n",
    "    opus_data = read_file(file_path)\n",
    "    # Assuming the spectral data is stored in the 'AB' key\n",
    "    spectral_data = opus_data['AB']\n",
    "    return spectral_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a9ea3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_to_common_wavenumbers(file_path, common_wavenumbers):\n",
    "    \"\"\"\n",
    "    Interpolates the spectral data from a file to a common set of wavenumbers.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path: The path to the file.\n",
    "    - common_wavenumbers: The common wavenumbers to interpolate the data to.\n",
    "    \n",
    "    Returns:\n",
    "    - A numpy array of the interpolated spectral data.\n",
    "    \"\"\"\n",
    "    original_wavenumbers = get_wavenumbers(file_path)\n",
    "    original_data = get_spectral_data(file_path)\n",
    "    interpolation_func = interp1d(original_wavenumbers, original_data, kind='linear', fill_value=\"extrapolate\")\n",
    "    interpolated_data = interpolation_func(common_wavenumbers)\n",
    "    return interpolated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f07103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_normalize(data):\n",
    "    \"\"\"\n",
    "    Normalizes a data array using Z-score normalization.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: A numpy array of spectral data.\n",
    "    \n",
    "    Returns:\n",
    "    - The Z-score normalized spectral data.\n",
    "    \"\"\"\n",
    "    mean = np.mean(data)\n",
    "    std_dev = np.std(data)\n",
    "    normalized_data = (data - mean) / std_dev\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09261ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_directory(folder_path, common_wavenumbers):\n",
    "    \"\"\"\n",
    "    Processes all files in a directory, interpolating and normalizing their spectral data.\n",
    "    \n",
    "    Parameters:\n",
    "    - folder_path: The path to the directory.\n",
    "    - common_wavenumbers: The common wavenumbers to interpolate the data to.\n",
    "    \n",
    "    Returns:\n",
    "    - A numpy array of all the normalized spectral data from the directory.\n",
    "    \"\"\"\n",
    "    normalized_data_list = []\n",
    "    files = list_files(folder_path)\n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        data = interpolate_to_common_wavenumbers(file_path, common_wavenumbers)\n",
    "        \n",
    "        # Cut the spectra to the wavenumbers from 800 to 1900 cm⁻¹\n",
    "        mask = (common_wavenumbers >= 900) & (common_wavenumbers <= 1800)\n",
    "        data = data[mask]\n",
    "        \n",
    "        normalized_data = z_score_normalize(data)\n",
    "        normalized_data_list.append(normalized_data)\n",
    "    return np.array(normalized_data_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb8acb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the first and last values as well as the size of the set to ensure it matches expectations\n",
    "print(\"First wavenumber:\", common_wavenumbers[0])\n",
    "print(\"Last wavenumber:\", common_wavenumbers[-1])\n",
    "print(\"Total number of points:\", len(common_wavenumbers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5211071c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process directories\n",
    "data_oe = process_directory(folder_path_oe, common_wavenumbers)\n",
    "data_re = process_directory(folder_path_re, common_wavenumbers)\n",
    "data_trachea = process_directory(folder_path_trachea, common_wavenumbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e15d301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a temporary training dataset and final test set\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the temporary training dataset into actual training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n",
    "\n",
    "# Define the parameter space for Bayesian Optimization\n",
    "param_space = {\n",
    "    'C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
    "    'gamma': Real(1e-6, 1e+1, prior='log-uniform'),\n",
    "    'kernel': Categorical(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'degree': Integer(1, 8),  # Only relevant for 'poly' kernel\n",
    "    'coef0': Real(0, 10)  # Only relevant for 'poly' and 'sigmoid' kernels\n",
    "}\n",
    "\n",
    "# Initialize the SVC model\n",
    "model = SVC(probability=True, random_state=42)\n",
    "\n",
    "# Initialize the Bayesian search with cross-validation\n",
    "bayes_search = BayesSearchCV(estimator=model,\n",
    "                             search_spaces=param_space,\n",
    "                             n_iter=32,  # Number of iterations of the search\n",
    "                             cv=5,  # 5-fold cross-validation\n",
    "                             n_jobs=-1,  # Use all available CPUs\n",
    "                             random_state=42)\n",
    "\n",
    "# Fit the model using Bayesian optimization\n",
    "bayes_search.fit(X_train, y_train)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['OE', 'RE', 'Trachea']\n",
    "               \n",
    "# Get the best parameters found by Bayesian optimization\n",
    "best_params = bayes_search.best_params_\n",
    "print(\"Best parameters found by Bayesian Optimization:\", best_params)\n",
    "\n",
    "# Evaluate the optimized model\n",
    "y_pred = bayes_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b35da3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Führe 5-fache Cross-Validation nur auf dem Trainingsdatensatz durch\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "\n",
    "# Berechne den Durchschnitt und die Standardabweichung der Scores\n",
    "average_score = np.mean(scores)\n",
    "std_deviation = np.std(scores)\n",
    "\n",
    "# Gib die Ergebnisse aus, auf 2 Dezimalstellen gerundet\n",
    "print(\"Cross-validation scores (on training set):\", scores)\n",
    "print(\"Average score:\", f\"{average_score:.2f}\")\n",
    "print(\"Standard deviation of scores:\", f\"{std_deviation:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aaa5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and plot ROC curves\n",
    "# Get the predicted probabilities for each class\n",
    "y_prob = model.predict_proba(X_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "plt.figure(figsize=(8, 6))\n",
    "for class_index in range(len(class_names)):\n",
    "    fpr, tpr, _ = roc_curve(y_test == class_index, y_prob[:, class_index])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve for {class_names[class_index]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Guessing')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168c5479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot learning curve\n",
    "def plot_learning_curve(estimator, title, X, y, cv=None, n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 10)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "# Initialize the Decision Tree model\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Plot learning curve for the Decision Tree model\n",
    "title = \"Learning Curves (Decision Tree)\"\n",
    "cv = 10  # Number of folds in cross-validation\n",
    "plot_learning_curve(model, title, X, y, cv=cv)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77eb609",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
